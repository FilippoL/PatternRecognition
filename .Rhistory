confmat = table(data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
#pixels_data = mnist.dat[,-1]
scaled_pixels_data <- (mnist.dat[,2:784] - min(mnist.dat[,2:784])) / (max(mnist.dat[,2:784]) - min(mnist.dat[,2:784]))
#down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
#scaled_pixels_data = (down_sampled_images - min(down_sampled_images))/max(down_sampled_images) - min(down_sampled_images)
#scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# results <- predict(model, newdata=test_mnist, type='probs')
# prediction <- max.col(results)
# prediction <- prediction - 1
# cl <- mean(prediction != test_mnist$label)
# print(paste('Accuracy', 1 - cl))
training_data <- mnist.dat[1:10000,]
validation_data <- mnist.dat[10001:42000,]
#training_data = sample_n(data_for_ml, 5000)
#validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#pixels_data = mnist.dat[,-1]
scaled_pixels_data <- mnist.dat[,2:784]/255
#down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
#scaled_pixels_data = (down_sampled_images - min(down_sampled_images))/max(down_sampled_images) - min(down_sampled_images)
#scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# results <- predict(model, newdata=test_mnist, type='probs')
# prediction <- max.col(results)
# prediction <- prediction - 1
# cl <- mean(prediction != test_mnist$label)
# print(paste('Accuracy', 1 - cl))
training_data <- mnist.dat[1:5000,]
validation_data <- mnist.dat[5001:42000,]
#training_data = sample_n(data_for_ml, 5000)
#validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
scaled_pixels_data = down_sampled_images/255
#scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# results <- predict(model, newdata=test_mnist, type='probs')
# prediction <- max.col(results)
# prediction <- prediction - 1
# cl <- mean(prediction != test_mnist$label)
# print(paste('Accuracy', 1 - cl))
training_data <- data_for_ml[1:5000,]
validation_data <- data_for_ml[5001:42000,]
#training_data = sample_n(data_for_ml, 5000)
#validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
# down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
scaled_pixels_data = pixels_data/255
#scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# results <- predict(model, newdata=test_mnist, type='probs')
# prediction <- max.col(results)
# prediction <- prediction - 1
# cl <- mean(prediction != test_mnist$label)
# print(paste('Accuracy', 1 - cl))
training_data <- data_for_ml[1:5000,]
validation_data <- data_for_ml[5001:42000,]
#training_data = sample_n(data_for_ml, 5000)
#validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
# down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
scaled_pixels_data = scale(pixels_data)
#scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# results <- predict(model, newdata=test_mnist, type='probs')
# prediction <- max.col(results)
# prediction <- prediction - 1
# cl <- mean(prediction != test_mnist$label)
# print(paste('Accuracy', 1 - cl))
training_data <- data_for_ml[1:5000,]
validation_data <- data_for_ml[5001:42000,]
#training_data = sample_n(data_for_ml, 5000)
#validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
dim(scaled_pixels_data)
dim(pixels_data)
View(head(scaled_pixels_data)))
View(head(scaled_pixels_data))
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
# down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
scaled_pixels_data = scale(pixels_data)
scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# results <- predict(model, newdata=test_mnist, type='probs')
# prediction <- max.col(results)
# prediction <- prediction - 1
# cl <- mean(prediction != test_mnist$label)
# print(paste('Accuracy', 1 - cl))
training_data <- data_for_ml[1:5000,]
validation_data <- data_for_ml[5001:42000,]
#training_data = sample_n(data_for_ml, 5000)
#validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
# down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
scaled_pixels_data = scale(pixels_data)
scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
# training_data <- data_for_ml[1:5000,]
# validation_data <- data_for_ml[5001:42000,]
training_data = sample_n(data_for_ml, 5000)
validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#install.packages("caret")
library(OpenImageR)
library(dplyr)
library(iterators)
library(nnet)
library(reshape2)
library(ggplot2)
library(caret)
library(glmnet)
mnist.dat <- read.csv("mnist.csv")
pixels_data = mnist.dat[,-1]
scaled_pixels_data = scale(pixels_data)
scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
mnist.dat$label = as.factor(mnist.dat$label)
show_image_from_data = function(data, row) {
sample_image = t(matrix(as.numeric(data[row,-1]),nrow=28,ncol=28,byrow=T)[c(28:1),,drop = FALSE])
return (image(sample_image, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1))
}
show_image_data = function(actual_digit) {
return (t(matrix(as.numeric(actual_digit),nrow=28,ncol=28,byrow=T))[,c(28:1),drop = FALSE])
}
show_image_from_data(mnist.dat, 1)
mnist.summary = data.frame(t(sapply( pixels_data , function(x) cbind(mean = mean(x) ,
sd = sd(x) ,
median = median(x) ,
minimum = min(x) ,
maximum = max(x) ,
s.size = length(x)))))
colnames(mnist.summary) = c("mean","sd","median","minimum","maximum","size")
head(mnist.summary[mnist.summary$sd==0,])
indices_of_useless_features = which(mnist.summary$sd == 0)
actual_digit = mnist.dat[90,-1]
actual_digit[,indices_of_useless_features] = 125
digit_example = show_image_data(actual_digit)
image(digit_example, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1)
indices_of_useless_features = which(mnist.summary$sd < 1)
actual_digit = mnist.dat[400,-1]
actual_digit[,indices_of_useless_features] = 125
digit_example = show_image_data(actual_digit)
image(digit_example, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1)
# Plot count of each digit's pixel in barplot and then display it in a table
label_distribution = table(mnist.dat[,1])
barplot(label_distribution, col=rainbow(10, 0.5), main="Digits in dataset")
# as.data.frame(mnist.dat) %>% group_by(label) %>% summarise(count = n())
expected_accuracy_on_majority_label_classification = label_distribution[2] / sum(label_distribution)
sprintf("Accuracy if 1 was predicted for all labels: %.2f %%", expected_accuracy_on_majority_label_classification * 100)
actual_digit = mnist.dat[450,-1]
indices_of_useful_features = which(actual_digit < 248)
actual_digit[,indices_of_useful_features] = 0
digit_example = show_image_data(actual_digit)
image(digit_example, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1)
hist(as.numeric(actual_digit), main="Frequency of pixels values", xlab="Pixel Value", ylab="Frequency")
hist.data = hist(as.matrix(mnist.dat[,-1]), breaks=32, main="Frequency of pixels values", xlab="Pixel Value", ylab="Frequency")
hist.data$counts = log10(hist.data$counts)
plot(hist.data, main="Frequency of scaled pixels values", xlab="Pixel Value", ylab="Frequency")
axis(side=1, at=seq(0, 256, 8))
# indices_of_useful_features =
# function(x) x[which(x < 248)] = 0
cleaned_images = t(apply(pixels_data, MARGIN = 1, FUN=function(x) replace(x, which(x < 5), 0)))
image_density = apply(cleaned_images, MARGIN=1, FUN=function(x) sum(x))
image_density_per_pixel = apply(data.frame(image_density), MARGIN=1, FUN=function(x) sum(x)/784) # Calculate density
data = cbind.data.frame(density=image_density,
density_per_pixel=scale(image_density_per_pixel),
scaled_density = scale(image_density),
label=mnist.dat$label)
data2 = cbind.data.frame(log_dens=scale(log(image_density_per_pixel)),
sqrt_dens=scale(sqrt(image_density_per_pixel)),
sin_dens=scale(sin(image_density_per_pixel)),
tanh_dens=tanh(scale(image_density_per_pixel)),  #TODO: Explain why scale after
scaled_density = scale(image_density),
squared_dens=scale(image_density^2),
label=mnist.dat$label)
head(data)
head(data2)
summary_per_digit = rbind.data.frame(tapply(data$density_per_pixel, data$label,  function(x) cbind(mean = mean(x) ,
sd = sd(x) ,
median = median(x) ,
minimum = min(x) ,
maximum = max(x),
s.size = length(x))
))
rownames(summary_per_digit) = c("mean","sd","median","minimum","maximum","size")
#TODO: Plot all distributions
data.frame(t(summary_per_digit))
cormat = dist(t(summary_per_digit[c("mean","sd"),]))
data.frame(as.matrix(cormat))
cormat = dist(t(summary_per_digit[c("mean","sd","median","minimum","maximum"),]))
melted_cormat <- melt(as.matrix(cormat))
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + geom_tile()
density_model = multinom(label ~ density_per_pixel, data, maxit=1000)
density_model
density_model2 = multinom(label ~ scaled_density + log_dens, data2, maxit=1000)
density_model2
predicted = predict(density_model2, data2)
confmat = table(data2$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
predicted = predict(density_model, data)
confmat = table(data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
# down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
# scaled_pixels_data = scale(pixels_data)
# scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
training_data = sample_n(data_for_ml, 5000)
validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
#trained_model = glmnet(as.matrix(training_data[,-1]), training_data[,1], family="multinomial")
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
# trained_model = multinom(label ~ ., training_data, maxit=50, family="multinomial", MaxNWts=5000)
predicted = predict(trained_model, training_data[,-1])
#predicted = melt(predicted, predicted[,,1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#install.packages("caret")
install.packages("e1071")
library(OpenImageR)
library(dplyr)
library(iterators)
library(nnet)
library(reshape2)
library(ggplot2)
library(caret)
library(glmnet)
library(e1071)
#install.packages("caret")
install.packages("e1071")
#install.packages("caret")
#install.packages("e1071")
library(OpenImageR)
library(dplyr)
library(iterators)
library(nnet)
library(reshape2)
library(ggplot2)
library(caret)
library(glmnet)
library(e1071)
trained_model = svm(label ~., data = training_data)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
trained_model = nnet(label ~., data = training_data, size=5)
trained_model = nnet(label ~., data = training_data, size=5,MaxNWts=5000)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
View(predicted)
predicted = predict(trained_model, validation_data[,-1], type="class")
head(predicted)
trained_model = nnet(label ~., data = training_data, size=5,MaxNWts=5000)
predicted = predict(trained_model, validation_data[,-1], type="class")
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
trained_model <- cv.glmnet(as.matrix(training_data[,-1]), training_data$labels,family="multinomial", type.measure="class")
head(training_data)
View(head(training_data))
trained_model <- cv.glmnet(as.matrix(training_data[,2:]), training_data$labels,family="multinomial", type.measure="class")
trained_model <- cv.glmnet(as.matrix(training_data[,-c(1)]), training_data$labels,family="multinomial", type.measure="class")
View(head(as.matrix(training_data[,-c(1)])))
View(training_data$labels)
trained_model <- cv.glmnet(as.matrix(training_data[,-c(1)]), training_data$label,family="multinomial", type.measure="class")
plot(trained_model)
#install.packages("caret")
#install.packages("e1071")
library(OpenImageR)
library(dplyr)
library(iterators)
library(nnet)
library(reshape2)
library(ggplot2)
library(caret)
library(glmnet)
library(e1071)
mnist.dat <- read.csv("mnist.csv")
pixels_data = mnist.dat[,-1]
scaled_pixels_data = scale(pixels_data)
scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
mnist.dat$label = as.factor(mnist.dat$label)
show_image_from_data = function(data, row) {
sample_image = t(matrix(as.numeric(data[row,-1]),nrow=28,ncol=28,byrow=T)[c(28:1),,drop = FALSE])
return (image(sample_image, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1))
}
show_image_data = function(actual_digit) {
return (t(matrix(as.numeric(actual_digit),nrow=28,ncol=28,byrow=T))[,c(28:1),drop = FALSE])
}
show_image_from_data(mnist.dat, 1)
mnist.summary = data.frame(t(sapply( pixels_data , function(x) cbind(mean = mean(x) ,
sd = sd(x) ,
median = median(x) ,
minimum = min(x) ,
maximum = max(x) ,
s.size = length(x)))))
colnames(mnist.summary) = c("mean","sd","median","minimum","maximum","size")
head(mnist.summary[mnist.summary$sd==0,])
indices_of_useless_features = which(mnist.summary$sd == 0)
actual_digit = mnist.dat[90,-1]
actual_digit[,indices_of_useless_features] = 125
digit_example = show_image_data(actual_digit)
image(digit_example, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1)
indices_of_useless_features = which(mnist.summary$sd < 1)
actual_digit = mnist.dat[400,-1]
actual_digit[,indices_of_useless_features] = 125
digit_example = show_image_data(actual_digit)
image(digit_example, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1)
# Plot count of each digit's pixel in barplot and then display it in a table
label_distribution = table(mnist.dat[,1])
barplot(label_distribution, col=rainbow(10, 0.5), main="Digits in dataset")
# as.data.frame(mnist.dat) %>% group_by(label) %>% summarise(count = n())
expected_accuracy_on_majority_label_classification = label_distribution[2] / sum(label_distribution)
sprintf("Accuracy if 1 was predicted for all labels: %.2f %%", expected_accuracy_on_majority_label_classification * 100)
actual_digit = mnist.dat[450,-1]
indices_of_useful_features = which(actual_digit < 248)
actual_digit[,indices_of_useful_features] = 0
digit_example = show_image_data(actual_digit)
image(digit_example, axes = FALSE, col = grey(seq(0, 1, length = 256)), asp=1)
hist(as.numeric(actual_digit), main="Frequency of pixels values", xlab="Pixel Value", ylab="Frequency")
hist.data = hist(as.matrix(mnist.dat[,-1]), breaks=32, main="Frequency of pixels values", xlab="Pixel Value", ylab="Frequency")
hist.data$counts = log10(hist.data$counts)
plot(hist.data, main="Frequency of scaled pixels values", xlab="Pixel Value", ylab="Frequency")
axis(side=1, at=seq(0, 256, 8))
# indices_of_useful_features =
# function(x) x[which(x < 248)] = 0
cleaned_images = t(apply(pixels_data, MARGIN = 1, FUN=function(x) replace(x, which(x < 5), 0)))
image_density = apply(cleaned_images, MARGIN=1, FUN=function(x) sum(x))
image_density_per_pixel = apply(data.frame(image_density), MARGIN=1, FUN=function(x) sum(x)/784) # Calculate density
data = cbind.data.frame(density=image_density,
density_per_pixel=scale(image_density_per_pixel),
scaled_density = scale(image_density),
label=mnist.dat$label)
data2 = cbind.data.frame(log_dens=scale(log(image_density_per_pixel)),
sqrt_dens=scale(sqrt(image_density_per_pixel)),
sin_dens=scale(sin(image_density_per_pixel)),
tanh_dens=tanh(scale(image_density_per_pixel)),  #TODO: Explain why scale after
scaled_density = scale(image_density),
squared_dens=scale(image_density^2),
label=mnist.dat$label)
head(data)
head(data2)
summary_per_digit = rbind.data.frame(tapply(data$density_per_pixel, data$label,  function(x) cbind(mean = mean(x) ,
sd = sd(x) ,
median = median(x) ,
minimum = min(x) ,
maximum = max(x),
s.size = length(x))
))
rownames(summary_per_digit) = c("mean","sd","median","minimum","maximum","size")
#TODO: Plot all distributions
data.frame(t(summary_per_digit))
cormat = dist(t(summary_per_digit[c("mean","sd"),]))
data.frame(as.matrix(cormat))
cormat = dist(t(summary_per_digit[c("mean","sd","median","minimum","maximum"),]))
melted_cormat <- melt(as.matrix(cormat))
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + geom_tile()
density_model = multinom(label ~ density_per_pixel, data, maxit=1000)
density_model
density_model2 = multinom(label ~ scaled_density + log_dens, data2, maxit=1000)
density_model2
predicted = predict(density_model2, data2)
confmat = table(data2$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
predicted = predict(density_model, data)
confmat = table(data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
#pixels_data = mnist.dat[,-1]
# scaled_pixels_data <- mnist.dat[,2:784]/255
# down_sampled_images = pixels_data %>% as.matrix(ncol=28, nrow=28) %>% down_sample_image(factor=2)
# scaled_pixels_data = scale(pixels_data)
# scaled_pixels_data[is.na(scaled_pixels_data)] = 0 #Replacing NaN with 0
data_for_ml = cbind.data.frame(label=mnist.dat$label, scaled_pixels_data)
training_data = sample_n(data_for_ml, 5000)
validation_data = setdiff(data_for_ml, training_data) #TODO: check what is going on
trained_model = multinom(label ~., family = "multinomial", data = training_data, MaxNWts =10000000, maxit=50)
predicted = predict(trained_model, training_data[,-1])
confmat = table(training_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
trained_model = svm(label ~., data = training_data)
predicted = predict(trained_model, validation_data[,-1])
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
trained_model = nnet(label ~., data = training_data, size=5,MaxNWts=5000)
predicted = predict(trained_model, validation_data[,-1], type="class")
confmat = table(validation_data$label, predicted)
confmat
sum(diag(confmat))/sum(confmat)
trained_model <- cv.glmnet(as.matrix(training_data[,-c(1)]), training_data$label,family="multinomial", type.measure="class")
plot(trained_model)
predicted = predict(trained_model, validation_data[,-1], type="class")
library(OpenImageR)
#install.packages("caret")
#install.packages("e1071")
install.packages("OpenImageR")
install.packages("dplyr")
install.packages("iterators")
install.packages("nnet")
install.packages("reshape2")
install.packages("ggplot2")
install.packages("caret")
install.packages("glmnet")
install.packages("e1071")
library(OpenImageR)
#install.packages("caret")
#install.packages("e1071")
install.packages("OpenImageR")
install.packages("dplyr")
install.packages("iterators")
install.packages("nnet")
install.packages("reshape2")
install.packages("ggplot2")
install.packages("caret")
install.packages("glmnet")
install.packages("e1071")
library(OpenImageR)
install.packages("OpenImageR")
install.packages("OpenImageR")
#install.packages("caret")
#install.packages("e1071")
install.packages("OpenImageR")
install.packages("dplyr")
install.packages("iterators")
install.packages("nnet")
install.packages("reshape2")
install.packages("ggplot2")
install.packages("caret")
install.packages("glmnet")
install.packages("e1071")
install.packages("factoextra")
